![Museum, The Trustees of the British.
"Babylonian Cuneiform Lexical List" World History Encyclopedia.
worldhistory.org/image/5036/babylonian-cuneiform-lexical-list
2016-05-03](babylonian-cuneiform-lexical-list-5036.jpg)
A friend of mine noted a similarity between the *Dialogue of Pessimism* (ca. 1000 BC, in Akkadian) and most human–AI conversations: the master (user) asks his slave (chat) whether he should treat himself to this or that. The slave enthusiastically confirms the merits and obvious benefits — only for the master to immediately cast doubt, prompting the slave to just as readily affirm the downsides, citing proverbs and common sense.

Last time I asked my fine network about AI shortcomings they’d witnessed themselves, Anton brought up the same issue: AI will often make a U-turn after a simple “Are you sure?” and go to the same lengths "proving" its new answer as it did the original one.

[Yann LeCun at NVIDIA GTC 2025 (0:01:00)](https://www.youtube.com/watch?v=eyrDM3A_YFc&t=60s):  
there are ... questions in four areas:  
how you get machines to understand the physical world,  
how you get them to have persistent memory, which not too many people talk about,  
and then the last two are how you get them to reason and plan.

Writing started 2025-07-17 17:11, last edited 2025-08-04 17:11.
